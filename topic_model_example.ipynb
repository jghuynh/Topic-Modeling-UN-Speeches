{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtwpi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mtwpi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mtwpi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\mtwpi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pyLDAvis\\_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.087*\"love\" + 0.087*\"eating\" + 0.087*\"make-up\" + 0.087*\"u.s\"')\n",
      "(1, '0.119*\"daniel\" + 0.117*\"eat\" + 0.117*\"refusal\" + 0.117*\"hate\"')\n",
      "(2, '0.093*\"mooncakes\" + 0.093*\"force-feeding\" + 0.093*\"justine\" + 0.093*\"sick\"')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el2160826788726222405469074085\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el2160826788726222405469074085_data = {\"mdsDat\": {\"x\": [-0.07649380228309154, 0.015642689468918676, 0.060851112814172804], \"y\": [0.024274153966254455, -0.0737458059550561, 0.04947165198880166], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [39.571691750587696, 25.15994037491972, 35.26836787449258]}, \"tinfo\": {\"Term\": [\"eat\", \"refusal\", \"hate\", \"mooncake\", \"mooncakes\", \"force-feeding\", \"justine\", \"sick\", \"smoking\", \"weed\", \"eating\", \"make-up\", \"u.s\", \"climate\", \"important\", \"bad\", \"change\", \"daniel\", \"love\", \"eating\", \"make-up\", \"u.s\", \"climate\", \"important\", \"bad\", \"change\", \"love\", \"daniel\", \"mooncake\", \"eat\", \"refusal\", \"hate\", \"weed\", \"smoking\", \"sick\", \"force-feeding\", \"justine\", \"mooncakes\", \"eat\", \"refusal\", \"hate\", \"mooncake\", \"daniel\", \"weed\", \"smoking\", \"justine\", \"sick\", \"mooncakes\", \"force-feeding\", \"bad\", \"change\", \"important\", \"climate\", \"u.s\", \"make-up\", \"eating\", \"love\", \"mooncakes\", \"force-feeding\", \"justine\", \"sick\", \"smoking\", \"weed\", \"love\", \"daniel\", \"mooncake\", \"hate\", \"refusal\", \"eat\", \"change\", \"important\", \"bad\", \"climate\", \"u.s\", \"make-up\", \"eating\"], \"Freq\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.7569833948514975, 0.7569715249121258, 0.7569660764153651, 0.7564156485164147, 0.7563433262082213, 0.7563263969504289, 0.7561785091812082, 0.7602787624459088, 0.7517317574677458, 0.18967052336069465, 0.18966971257248622, 0.18966791262266347, 0.1896661126728407, 0.18998570916884627, 0.18997320681467203, 0.18973906739583674, 0.18973725123024981, 0.18973394321435938, 0.18973277567933922, 0.6494834724961152, 0.6494820703240256, 0.6494800495466024, 0.6494741934161108, 0.6565268303440508, 0.16299449447094438, 0.16299258710449904, 0.16281822288112813, 0.1628152845057934, 0.1628144700087708, 0.16281279977437002, 0.16290085824361145, 0.16289969320356645, 0.1628851147378707, 0.16288492915627062, 0.1628515450884327, 0.16284869950389802, 0.16283877088829335, 0.16338301986081605, 0.7214993622082746, 0.7214969342151865, 0.7214941015565834, 0.7214924828945246, 0.7210721510434612, 0.7210582189878834, 0.7187645748505167, 0.7205340037182584, 0.180771701803279, 0.1807694183335889, 0.18076545839248065, 0.18076213435432414, 0.18159260915688424, 0.18145177110542593, 0.18145038368080407, 0.181383093586644, 0.18089570287885748, 0.18089357838490527, 0.18089336159980812], \"Total\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.100715527339599, 1.1007138028009291, 1.1007133243826552, 1.1006836712593293, 1.100680212051518, 1.1006776388748445, 1.1006708115416588, 1.6424263571572415, 2.128792591530055, 1.0199164185800844, 1.0199153194229256, 1.0199154413391698, 1.019915580553032, 1.074038422627674, 1.0740379449626323, 1.0740468347961547, 1.0740469852198062, 1.074046267652071, 1.0740466078963846, 1.0199153194229256, 1.0199154413391698, 1.019915580553032, 1.0199164185800844, 2.128792591530055, 1.074038422627674, 1.0740379449626323, 1.074046267652071, 1.0740468347961547, 1.0740466078963846, 1.0740469852198062, 1.1006776388748445, 1.1006708115416588, 1.100680212051518, 1.1006836712593293, 1.1007133243826552, 1.1007138028009291, 1.100715527339599, 1.6424263571572415, 1.0740466078963846, 1.0740469852198062, 1.074046267652071, 1.0740468347961547, 1.0740379449626323, 1.074038422627674, 1.6424263571572415, 2.128792591530055, 1.0199164185800844, 1.019915580553032, 1.0199154413391698, 1.0199153194229256, 1.1006708115416588, 1.100680212051518, 1.1006776388748445, 1.1006836712593293, 1.1007133243826552, 1.1007138028009291, 1.100715527339599], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.4424, -2.4424, -2.4424, -2.4432, -2.4432, -2.4433, -2.4435, -2.4381, -2.4494, -3.8265, -3.8265, -3.8265, -3.8265, -3.8248, -3.8249, -3.8261, -3.8261, -3.8261, -3.8261, -2.1427, -2.1427, -2.1427, -2.1427, -2.1319, -3.5252, -3.5252, -3.5262, -3.5263, -3.5263, -3.5263, -3.5257, -3.5257, -3.5258, -3.5258, -3.526, -3.5261, -3.5261, -3.5228, -2.3753, -2.3753, -2.3753, -2.3753, -2.3759, -2.3759, -2.3791, -2.3766, -3.7594, -3.7594, -3.7594, -3.7594, -3.7548, -3.7556, -3.7556, -3.756, -3.7587, -3.7587, -3.7587], \"loglift\": [19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.5527, 0.5527, 0.5527, 0.552, 0.5519, 0.5518, 0.5517, 0.1568, -0.1139, -0.7551, -0.7551, -0.7551, -0.7552, -0.8052, -0.8052, -0.8065, -0.8065, -0.8065, -0.8065, 0.9286, 0.9286, 0.9286, 0.9286, 0.2036, -0.5055, -0.5056, -0.5066, -0.5067, -0.5067, -0.5067, -0.5306, -0.5306, -0.5307, -0.5307, -0.531, -0.531, -0.531, -0.9279, 0.6443, 0.6443, 0.6443, 0.6443, 0.6437, 0.6437, 0.2158, -0.0411, -0.6881, -0.6881, -0.6881, -0.6881, -0.7597, -0.7605, -0.7605, -0.7609, -0.7636, -0.7636, -0.7636]}, \"token.table\": {\"Topic\": [1, 1, 1, 1, 2, 3, 2, 1, 3, 2, 1, 3, 1, 3, 1, 2, 3, 2, 3, 3, 1, 3], \"Freq\": [0.9085312217501201, 0.9085368572637501, 0.908526242472432, 0.4697498497405315, 0.4697498497405315, 0.4697498497405315, 0.9804735559475725, 0.9084999485897816, 0.9310579646525871, 0.9804733049158508, 0.9085290977804863, 0.9310585866901799, 0.6088553046182409, 0.6088553046182409, 0.9085013719782127, 0.980472499297725, 0.931058291742654, 0.9804734387460392, 0.9310580950501957, 0.9310658014366446, 0.9085017668527442, 0.9310653873568728], \"Term\": [\"bad\", \"change\", \"climate\", \"daniel\", \"daniel\", \"daniel\", \"eat\", \"eating\", \"force-feeding\", \"hate\", \"important\", \"justine\", \"love\", \"love\", \"make-up\", \"mooncake\", \"mooncakes\", \"refusal\", \"sick\", \"smoking\", \"u.s\", \"weed\"]}, \"R\": 19, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el2160826788726222405469074085\", ldavis_el2160826788726222405469074085_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el2160826788726222405469074085\", ldavis_el2160826788726222405469074085_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el2160826788726222405469074085\", ldavis_el2160826788726222405469074085_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()\n",
    "# import spacy\n",
    "# spacy.load('en_core_web_sm')\n",
    "# from spacy.lang.en import English\n",
    "# parser = English()\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import random\n",
    "from gensim import corpora\n",
    "import pickle\n",
    "import gensim\n",
    "\n",
    "nltk.download('stopwords')\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "specialChars = \"!@#$%^&*()\\'\\\"?.,~<>_-+{}[]|;\"\n",
    "myPunc = set(specialChars)\n",
    "en_stop.update(myPunc)\n",
    "en_stop.add('n\\'t')\n",
    "\n",
    "# def tokenize(text):\n",
    "#     '''\n",
    "#     Tokenizes the text\n",
    "    \n",
    "#     @param text the given String\n",
    "#     @return the lda tokens\n",
    "#     '''\n",
    "#     lda_tokens = []\n",
    "# #     print(\"got here@\")\n",
    "#     tokens = parser(text)\n",
    "# #     print(tokens)\n",
    "#     for token in tokens:\n",
    "#         if not token.orth_.isspace():\n",
    "#             lda_tokens.append(token.lower_)\n",
    "# #             continue\n",
    "            \n",
    "#     return lda_tokens\n",
    "\n",
    "# def get_lemma(word):\n",
    "#     lemma = wn.morphy(word)\n",
    "#     if lemma is None:\n",
    "#         return word\n",
    "#     else:\n",
    "#         return lemma\n",
    "    \n",
    "def get_lemma(word):\n",
    "    '''\n",
    "    Lemmatizes the word\n",
    "    \n",
    "    @param String word the given word to lemmatize\n",
    "    @return the newly lemmatized core word\n",
    "    '''\n",
    "    \n",
    "#     print(\"word lemonizer\", WordNetLemmatizer().lemmatize(word))\n",
    "    return WordNetLemmatizer().lemmatize(word)\n",
    "\n",
    "def removePunctuation(word):\n",
    "    '''\n",
    "    Removes punctuation from a given word\n",
    "    '''\n",
    "    \n",
    "    lastIndex = len(word) - 1\n",
    "    if word[lastIndex] in myPunc:\n",
    "        # eradicate the last index value\n",
    "        return word[:-1]\n",
    "\n",
    "    return word\n",
    "    \n",
    "\n",
    "def prepare_text_for_lda(text):\n",
    "    '''\n",
    "    Tokenizes, splits, removes stopwords from the text\n",
    "    \n",
    "    @param String text the given text\n",
    "    @return the tokens\n",
    "    '''\n",
    "    text = text.lower()\n",
    "    #     tokens = tokenize(text)\n",
    "#     print(text, tokens)\n",
    "    tokens = text.split(\" \")\n",
    "    tokens = [token for token in tokens if len(token) > 1]\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    tokens = [removePunctuation(token) for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def generate_viz(data, NUM_TOPICS=5):\n",
    "    '''\n",
    "    Graphs the data by topic\n",
    "    \n",
    "    @param list data the given list of Strings\n",
    "    @param int NUM_TOPICS number of topics to graph; default set to 5\n",
    "    @return the graph, dictionary, and corpus\n",
    "    '''\n",
    "    text_data = []\n",
    "\n",
    "    for line in data:\n",
    "        tokens = prepare_text_for_lda(line)\n",
    "        text_data.append(tokens)\n",
    "\n",
    "    dictionary = corpora.Dictionary(text_data)\n",
    "    corpus = [dictionary.doc2bow(text) for text in text_data]\n",
    "    pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
    "    dictionary.save('dictionary.gensim')\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15, random_state = 420)\n",
    "    ldamodel.save('model5.gensim')\n",
    "\n",
    "    topics = ldamodel.print_topics(num_words=4)\n",
    "    for topic in topics:\n",
    "        print(topic)\n",
    "\n",
    "    dictionary = gensim.corpora.Dictionary.load('dictionary.gensim')\n",
    "    corpus = pickle.load(open('corpus.pkl', 'rb'))\n",
    "    lda = gensim.models.ldamodel.LdaModel.load('model5.gensim')\n",
    "\n",
    "    lda_display = gensimvis.prepare(lda, corpus, dictionary, sort_topics=False)\n",
    "    return lda_display, dictionary, corpus\n",
    "\n",
    "list_of_strings = [\"Climate change is important, not bad\", \"I hate Daniel for his refusal to eat a mooncake\",\n",
    "                  \"I love smoking weed!\", \"Daniel is sick of Justine force-feeding him mooncakes\", \"Daniel loves eating make-up in U.S.\"]\n",
    "viz, dictionary, corpus = generate_viz(list_of_strings, 3)\n",
    "pyLDAvis.display(viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtwpi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# parser(list_of_strings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtwpi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# !{sys.executable} -m pip install pyldavis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
